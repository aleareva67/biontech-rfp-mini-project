{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec10682b-15b1-4240-81ac-56c663201695",
   "metadata": {},
   "source": [
    "# Data Cleaning & Validation - Evolution Data\n",
    "\n",
    "**Author:** Alan Meeson <alan.meeson@capgemini.com>\n",
    "\n",
    "**Date:** 2023-02-06\n",
    "\n",
    "This notebook captures assumptions about the data, and validation of those assumptions.\n",
    "This can serve as a template for the Cleaning and Validation stage of the ETL process for the evolution data.\n",
    "\n",
    "Key findings are:\n",
    "- The rows for South Africa are corrupted.  The `location` entry is missing the closing ' \" '\n",
    "- There are some `perc_sequences` entries which are below 0 by -0.01.  Typically for variants 'other' and 'non_who'\n",
    "- There are some `perc_sequences` entries which are off by 0.01 in addition to the ones noted above.\n",
    "- There is some duplication in counts between the variants 'other' and 'non_who'; if we include both in the sum, the totals for a location/day don't add up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a3ba66-9543-4638-ba27-f445584e7204",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178f596-c82b-4676-9bb8-d84c054b0c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "evolution_filename = os.path.join(data_dir, 'raw', 'Data1_Covid Variants evolution.csv')\n",
    "fixed_evolution_filename = os.path.join(data_dir, 'fixed', 'Data1_Covid Variants evolution.csv')\n",
    "cleaned_evolution_filename = os.path.join(data_dir, 'cleaned', 'covid_variants_evolution.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c79590-bdce-427b-8390-0c2a00d0e3d6",
   "metadata": {},
   "source": [
    "## Explore the Evolution Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c561c7-3fec-44c5-ad7a-b4dff7ece8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df = pd.read_csv(evolution_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a660557e-8751-421e-b75a-f4443dfd7ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29077a2d-ea6a-4b2b-b7a9-9865c56d207e",
   "metadata": {},
   "source": [
    "### Validate formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006ba62-7398-4643-8600-b330b44c5d13",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Location\n",
    "Assume that locations are purely letters with optional brackets and start with a captial letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39013d2-7157-43eb-9d85-5760bf7f34f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "location_pattern = re.compile('^[A-Z][A-Za-z\\(\\) ]+$')\n",
    "all(evolution_df['location'].str.fullmatch(location_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d6126-50f7-4dce-9fdc-867578e46639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df[~evolution_df['location'].str.fullmatch(location_pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e081667-6cfa-45a4-b5b1-f33ce9ff5a15",
   "metadata": {},
   "source": [
    "##### Correct the row formatting issue\n",
    "\n",
    "We correct this here, rather than with the other cleaning, as if we do not then it will throw off all those tests too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea062c6-a06f-40f9-aa07-6a50ade47e07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_columns = ['location', 'date', 'variant', 'num_sequences', 'perc_sequences', 'num_sequences_total']\n",
    "expected_num_columns = len(expected_columns)\n",
    "\n",
    "# If the output path does not yet exist, create it\n",
    "if not os.path.exists(os.path.dirname(fixed_evolution_filename)):\n",
    "    os.makedirs(os.path.dirname(fixed_evolution_filename))\n",
    "\n",
    "# Scan each line in the csv file for quote errors resulting in too few columns, fix if possible\n",
    "with open(fixed_evolution_filename, 'w', newline='') as outfp:\n",
    "    writer = csv.writer(outfp, quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    with open(evolution_filename, 'r', newline='') as fp:\n",
    "        reader = csv.reader(fp)\n",
    "        \n",
    "        for line in reader:\n",
    "            # File is known to have no commas in actual data, so if any are present this is an error.            \n",
    "            # Particularly if the line has fewer than the expected number of rows            \n",
    "            if (len(line) < expected_num_columns) and any([',' in element for element in line]):\n",
    "                new_line = []\n",
    "                \n",
    "                for element in line:\n",
    "                    new_line.extend(element.split(','))\n",
    "        \n",
    "                new_line = [element.removesuffix('\"') for element in new_line]\n",
    "                \n",
    "                if len(new_line) == expected_num_columns:\n",
    "                    writer.writerow(new_line)\n",
    "                else:\n",
    "                    print(\"Could not correct bad line: %s\" % line)\n",
    "            else:\n",
    "                writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e471aed6-44b0-4fb0-a2ee-3588c0632ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the corrected data, and check the fix\n",
    "evolution_df = pd.read_csv(fixed_evolution_filename)\n",
    "\n",
    "location_pattern = re.compile('^[A-Z][A-Za-z\\(\\) ]+$')\n",
    "all(evolution_df['location'].str.fullmatch(location_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8903d69-f8d0-499e-a432-289393bdb3a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Date\n",
    "\n",
    "Assume dates are always in the DD.MM.YYYY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152210e-921d-4c10-9bce-dae5a520d350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_pattern = re.compile('^[0-3][0-9]\\.[01][0-9]\\.[12][0-9]{3}$')\n",
    "all(evolution_df['date'].str.fullmatch(date_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9973ac92-3f62-46a6-a1e0-954729fd7d5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variant\n",
    "\n",
    "Assume that variants start with something other than a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3427d90-bca3-4146-824a-cb382c896837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variant_pattern = re.compile('^[A-Za-z\\.:_][A-Za-z0-9\\.:_]+$')\n",
    "all(evolution_df['variant'].str.fullmatch(variant_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f2b83-74af-4bc3-ae92-855ebfa9f7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df['variant'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf45e1-d2c9-4a7e-94ac-1a1375b6003d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29e090-03f6-42dc-826f-072858f78c3c",
   "metadata": {},
   "source": [
    "##### Num_Sequences\n",
    "\n",
    "Should be a number greater than 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09afd8d6-60bd-4d83-afae-b3c8f09607db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all(~evolution_df['num_sequences'].isna() & (evolution_df['num_sequences'] >= 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5959f5a-1523-43c6-a860-f3ec181f674a",
   "metadata": {},
   "source": [
    "##### Perc Sequences \n",
    "Should be a number between 0 & 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6857b28-4e94-414a-991a-2bd3605dbe4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_perc_sequences_valid = ~evolution_df['perc_sequences'].isna() & (evolution_df['perc_sequences'] >= 0) & (evolution_df['perc_sequences'] <= 100)\n",
    "all(is_perc_sequences_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a28e42-3996-4dc5-aade-7d1b5bf0a60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df[~is_perc_sequences_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8be52-99d6-43bf-bb98-6f48bd332a5c",
   "metadata": {},
   "source": [
    "##### Num Sequences Total\n",
    "\n",
    "Should be a number greater than zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b8680-7b9d-4c1d-b7f3-3eda3c97b9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_num_sequences_total_valid = ~evolution_df['num_sequences_total'].isna() & (evolution_df['num_sequences_total'] >= 0)\n",
    "all(is_num_sequences_total_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697bb9c-e714-45ba-abe9-169deea840c1",
   "metadata": {},
   "source": [
    "##### num_sequences should be less than or equal to num_sequences total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79a958-b69f-4ead-9f9f-dc6da7b7c29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_part_of_the_whole = evolution_df['num_sequences'] <= evolution_df['num_sequences_total']\n",
    "all(is_part_of_the_whole)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17a2784-5ac1-4cd5-aec3-7ca5b18d0215",
   "metadata": {},
   "source": [
    "##### perc_sequences should be approximately equal to 100 * (num_sequences / num_sequences_total)\n",
    "However, several are out by 0.01; so it's probably worth re-calculating these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de30c0-4fe2-40b0-8077-78ff15e4620c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_the_perc_right = abs(evolution_df['perc_sequences'] - ((evolution_df['num_sequences'] / evolution_df['num_sequences_total']) * 100)) < 0.01\n",
    "all(is_the_perc_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b36a16-83d1-4b46-88e4-2a9f0d025355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(~is_the_perc_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832df6e8-23cb-445f-88c0-0dc320378f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df[~is_the_perc_right]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37402bc3-cb41-45c0-9c65-f989e4c93cae",
   "metadata": {},
   "source": [
    "##### sum of num_sequences grouped by date and country should be equal to the num_sequences_total for that group.\n",
    "Which they are, but only if we exclude either \"other\" or \"non_who\", as it seems those categories overlap somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884b0a4-eca0-4129-8612-b75aa72a1fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_sums = evolution_df[['location', 'date', 'num_sequences']].groupby(['location', 'date']).sum()\n",
    "sequence_totals = evolution_df[['location', 'date', 'num_sequences_total']].groupby(['location', 'date']).first()\n",
    "combined_totals = pd.concat([sequence_sums, sequence_totals], axis=1)\n",
    "does_it_add_up = combined_totals['num_sequences'] == combined_totals['num_sequences_total']\n",
    "all(does_it_add_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49921815-a255-438a-a96b-139e80f08d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(~does_it_add_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec9f94-4b8c-410a-b0c9-093cb85e04f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sequence_sums = evolution_df.loc[~(evolution_df['variant'] == 'non_who'), ['location', 'date', 'num_sequences']].groupby(['location', 'date']).sum()\n",
    "sequence_totals = evolution_df[['location', 'date', 'num_sequences_total']].groupby(['location', 'date']).first()\n",
    "combined_totals = pd.concat([sequence_sums, sequence_totals], axis=1)\n",
    "does_it_add_up = combined_totals['num_sequences'] == combined_totals['num_sequences_total']\n",
    "all(does_it_add_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c0b68-c2f9-43f6-9536-ccbf85b6cff1",
   "metadata": {},
   "source": [
    "## Perform the data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4143ec-7ec1-40da-9fd6-fbc90f68bf0f",
   "metadata": {},
   "source": [
    "### Load a fresh copy of the data set and parse dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dadcaee-ef37-4d99-8267-75c494cb903e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_date_parser = lambda x: datetime.datetime.strptime(x, \"%d.%m.%Y\")\n",
    "evolution_df = pd.read_csv(fixed_evolution_filename, parse_dates=['date'], date_parser=custom_date_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144232f-4413-4321-a9f1-79160d4718eb",
   "metadata": {},
   "source": [
    "### Recalculate the perc_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c83f3-9553-493e-bf9e-f3c49090a3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evolution_df['perc_sequences'] = 100 * evolution_df['num_sequences'] / evolution_df['num_sequences_total']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4f4f4-4d70-4acb-bc1a-7110947daa1e",
   "metadata": {},
   "source": [
    "### Re-apply the basic validation checks to see that it is all correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e1dac-8239-481c-a8e3-9f5ad30211fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Location is a string which starts with a captial letter, and may contain\n",
    "# letters, spaces, brackets, dashes and apostrophes only.\n",
    "location_pattern = re.compile('^[A-Z][A-Za-z\\(\\)\\'\\- ]+$')\n",
    "all(evolution_df['location'].str.fullmatch(location_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe72ec-8972-4f11-afc5-8831beacc11c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variant is a string which starts with something other than a number, and may contain\n",
    "# letters, ., :, _ and numbers only.\n",
    "variant_pattern = re.compile('^[A-Za-z\\.:_][A-Za-z0-9\\.:_]+$')\n",
    "all(evolution_df['variant'].str.fullmatch(variant_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a75e83-758d-4ec0-96b8-ddbab0e8e7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_sequences is a number greater than or equal to zero, and is not null\n",
    "all(~evolution_df['num_sequences'].isna() & (evolution_df['num_sequences'] >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac1e4be-82d0-49aa-b1fe-9c9b5fb4ab2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perc_sequences is a floating point number in the range 0 <= x <= 100.\n",
    "is_perc_sequences_valid = ~evolution_df['perc_sequences'].isna() & \\\n",
    "    (evolution_df['perc_sequences'] >= 0) & \\\n",
    "    (evolution_df['perc_sequences'] <= 100)\n",
    "all(is_perc_sequences_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed3b4e-b2bb-4775-8381-a70e24b852bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Num_sequences_total is a number greater than or equal to zero and is not null\n",
    "is_num_sequences_total_valid = ~evolution_df['num_sequences_total'].isna() & (evolution_df['num_sequences_total'] >= 0)\n",
    "all(is_num_sequences_total_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e9442f-42ff-4fe9-ab88-d0fc243b8d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Num_sequences should always be less than or equal to num_sequences_total\n",
    "is_part_of_the_whole = evolution_df['num_sequences'] <= evolution_df['num_sequences_total']\n",
    "all(is_part_of_the_whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80457abf-32f9-4969-86e4-ec2bd527abf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If we exclude the non_who row, the sum of num_sequences for a given location/date pair will\n",
    "# add up to the num_sequences_total for that location/date pair\n",
    "sequence_sums = evolution_df.loc[\n",
    "    ~(evolution_df['variant'] == 'non_who'), \n",
    "    ['location', 'date', 'num_sequences']\n",
    "].groupby(['location', 'date']).sum()\n",
    "\n",
    "sequence_totals = evolution_df[['location', 'date', 'num_sequences_total']].groupby(['location', 'date']).first()\n",
    "\n",
    "combined_totals = pd.concat([sequence_sums, sequence_totals], axis=1)\n",
    "does_it_add_up = combined_totals['num_sequences'] == combined_totals['num_sequences_total']\n",
    "all(does_it_add_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5b199-0f5f-4641-bc66-cfd11203f9fa",
   "metadata": {},
   "source": [
    "### Create a parquet file for the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bef5d3-8641-47ca-87e5-334bfd682ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the output path does not yet exist, create it\n",
    "if not os.path.exists(os.path.dirname(cleaned_evolution_filename)):\n",
    "    os.makedirs(os.path.dirname(cleaned_evolution_filename))\n",
    "    \n",
    "evolution_df.to_parquet(cleaned_evolution_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
